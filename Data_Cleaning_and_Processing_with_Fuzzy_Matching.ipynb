{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+HZQ8uJo/fBn2YlfWHzvV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SBOSE550/Customer-Data-Processing-and-Validation-System/blob/main/Data_Cleaning_and_Processing_with_Fuzzy_Matching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Processing with Fuzzy Matching\n",
        "\n",
        "This notebook performs data cleaning and customer name matching using fuzzy logic.  \n",
        "It processes two datasets:\n",
        "- **Existing Customer Log** – updates names based on fuzzy matches with a master list.\n",
        "- **New Customer Log** – classifies new customers as either genuine new or potentially matching an existing master record.\n",
        "\n",
        "The matching process is based on the following logic:\n",
        "- If the fuzzy match score is **above 90**, the name is automatically corrected.\n",
        "- If the score is **between 55 and 90**, the user is prompted to confirm the suggested match.\n",
        "- If the score is **below 55**, no match is made, and the record is flagged accordingly.\n",
        "\n",
        "The final cleaned data is consolidated and exported to an Excel workbook with multiple sheets."
      ],
      "metadata": {
        "id": "orOefpQDWMzK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Required Libraries\n",
        "\n",
        "We import the necessary libraries, including:\n",
        "- **pandas** and **numpy** for data manipulation.\n",
        "- **fuzzywuzzy** for fuzzy string matching.\n",
        "- **openpyxl** for Excel file operations."
      ],
      "metadata": {
        "id": "hT_Qc81yOLLY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suA677fPN7Vu",
        "outputId": "6258bbee-25fd-4674-bb7c-8ae048933998"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Installing collected packages: fuzzywuzzy\n",
            "Successfully installed fuzzywuzzy-0.18.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
            "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from fuzzywuzzy import fuzz, process\n",
        "import openpyxl\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Extraction Functions\n",
        "\n",
        "The following function extracts data from a specified sheet in an Excel file.\n",
        "## Data Preprocessing\n",
        "\n",
        "We clean the customer name and FPR (or salesperson) fields by stripping whitespace and converting text to lowercase.\n",
        "## Classifying Existing Customers\n",
        "\n",
        "This function matches the customer names from the existing customer log with the master list using fuzzy matching.\n",
        "- If a match score is above 90, the customer name is automatically corrected.\n",
        "- If the score is between 55 and 90, the user is prompted to confirm the replacement.\n",
        "- If the score is below 55, the record is collected for further review (e.g., via mail).\n",
        "## Classifying New Customers\n",
        "\n",
        "This function processes the new customer log. It attempts to match each new customer with the master dataset.\n",
        "- If a direct match is found (score ≥ 90), the customer name is updated automatically.\n",
        "- For scores between 55 and 90, the user is prompted to confirm the match.\n",
        "- If no sufficient match is found (score < 55), the customer is classified as a genuine new customer."
      ],
      "metadata": {
        "id": "qJ4S_thSSSap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_data_from_sheet(excel_file, sheet_name):\n",
        "    \"\"\"Extracts data from a specific sheet in an Excel file.\n",
        "\n",
        "    Args:\n",
        "        excel_file: Path to the Excel file.\n",
        "        sheet_name: Name of the sheet to extract data from.\n",
        "\n",
        "    Returns:\n",
        "        A list of lists representing the data in the sheet, or None if the sheet doesn't exist.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        workbook = openpyxl.load_workbook(excel_file)\n",
        "        sheet = workbook[sheet_name]  # Access the sheet by name\n",
        "        data = []\n",
        "        for row in sheet.iter_rows():\n",
        "            row_data = [cell.value for cell in row]\n",
        "            data.append(row_data)\n",
        "        return data\n",
        "    except KeyError:\n",
        "        print(f\"Sheet '{sheet_name}' not found.\")\n",
        "        return None\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{excel_file}' not found.\")\n",
        "        return None\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_column(df, column1,column2):\n",
        "    df[column1] = df[column1].str.strip().str.lower()\n",
        "    df[column2] = df[column2].str.strip().str.lower()\n",
        "    return df\n",
        "\n",
        "def classify_existing_customer(existing_customers_df, master_df):\n",
        "  mail=[]\n",
        "  for index, row in existing_customers_df.iterrows():\n",
        "    customer_name = row[\"Customer Name\"]\n",
        "    FPR = row[\"Name\"]\n",
        "\n",
        "    # Filter master list by FPR (if applicable)\n",
        "    if FPR:\n",
        "      FPR_customers = master_df[master_df[\"FPR\"] == FPR]\n",
        "    else:\n",
        "      FPR_customers = master_df.copy()  # Consider all customers if no FPR filter\n",
        "\n",
        "    # Check if there are no matching FPR/customers\n",
        "    if FPR_customers.empty:\n",
        "      print(f\"No customers found for FPR: {FPR}. Skipping fuzzy matching for '{customer_name}'.\")\n",
        "      continue\n",
        "\n",
        "    # Perform fuzzy matching\n",
        "    matches = FPR_customers[\"Customer Name\"].apply(lambda x: fuzz.ratio(x.lower(), customer_name.lower()))\n",
        "    best_match_idx = matches.idxmax()\n",
        "    best_match_score = matches.max()\n",
        "\n",
        "    if best_match_score > 90:\n",
        "      existing_customers_df.at[index, \"Customer Name\"] = master_df.loc[best_match_idx, \"Customer Name\"]\n",
        "      print(f\"Auto-corrected '{customer_name}' to '{master_df.loc[best_match_idx, 'Customer Name']}' under {FPR} (Score: {best_match_score})\")\n",
        "\n",
        "    elif 55 <= best_match_score <= 90:  # Adjust threshold for suggestions\n",
        "      suggestion = master_df.loc[best_match_idx, \"Customer Name\"]\n",
        "      print(f\"Suggested match for '{customer_name}': '{suggestion}' Under {FPR} (Score: {best_match_score})\")\n",
        "      user_input = input(\"Replace? (yes/no): \").strip().lower()\n",
        "      if user_input == 'yes':\n",
        "        existing_customers_df.at[index, \"Customer Name\"] = suggestion\n",
        "        print(f\"Replaced '{customer_name}' with '{suggestion}' under {FPR}\")\n",
        "      else:\n",
        "        print(f\"Not maching with existing data '{customer_name}' under {FPR}\")\n",
        "        mail.append(row)\n",
        "\n",
        "    else:\n",
        "      print(f\"No match found for '{customer_name}' under {FPR} (Score: {best_match_score})\")\n",
        "      mail.append(row)\n",
        "\n",
        "  mail_df = pd.DataFrame(mail, columns=existing_customers_df.columns)\n",
        "\n",
        "  print(\"Cleaning complet for existing customers\")\n",
        "  return existing_customers_df,mail_df\n",
        "\n",
        "# Function to classify new customers based on fuzzy matching\n",
        "def classify_new_customers(master_df, new_customers):\n",
        "    genuine_new = []\n",
        "    existing_customers = []\n",
        "\n",
        "    for index, row in new_customers.iterrows():\n",
        "        new_customer_name = row['Customer Name']\n",
        "        FPR = row['Name']\n",
        "\n",
        "        # Filter master list by salesperson (if applicable)\n",
        "        if FPR:\n",
        "          master_names = master_df[master_df[\"FPR\"] == FPR]\n",
        "        else:\n",
        "          master_names = master_df.copy()  # Consider all customers if no salesperson filter\n",
        "\n",
        "        # Check if there are no matching salespeople/customers\n",
        "        if master_names.empty:\n",
        "          print(f\"No customers found for FPR: {FPR}. Skipping fuzzy matching for '{new_customer_name}'.\")\n",
        "          genuine_new.append(row)  # Add to genuine_new if no match found\n",
        "          continue\n",
        "\n",
        "\n",
        "        # Perform fuzzy matching against master dataset\n",
        "       # Handle cases where extractOne might return a single element or None\n",
        "        result = process.extractOne(new_customer_name, master_names['Customer Name'].tolist()) # Extract from 'Customer Name' column\n",
        "        if result:\n",
        "            match, score = result\n",
        "        else:\n",
        "            match, score = None, 0  # Default values if no match\n",
        "\n",
        "        if score >= 90:\n",
        "            # Direct match; replace with Master dataset's name\n",
        "            row['Customer Name'] = match\n",
        "            print(f\"Potential Match Found:\\nNew Customer: {new_customer_name}\\nMaster Dataset Match: {match} under {FPR} (Score: {score})\")\n",
        "            existing_customers.append(row)\n",
        "        elif 55 <= score < 90:\n",
        "            # Prompt for manual input\n",
        "            print(f\"Potential Match Found:\\nNew Customer: {new_customer_name}\\nMaster Dataset Match: {match} under {FPR} (Score: {score})\")\n",
        "            user_input = input(\"Is this a match? (yes/no): \").strip().lower()\n",
        "\n",
        "            if user_input == \"yes\":\n",
        "                row['Customer Name'] = match\n",
        "                existing_customers.append(row)\n",
        "            else:\n",
        "                genuine_new.append(row)\n",
        "        else:\n",
        "            # Genuine new customer\n",
        "            genuine_new.append(row)\n",
        "\n",
        "    # Convert lists back to DataFrames\n",
        "    genuine_new_df = pd.DataFrame(genuine_new, columns=new_customers.columns)\n",
        "    existing_customers_df = pd.DataFrame(existing_customers, columns=new_customers.columns)\n",
        "    genuine_new_df['Business Status'] = 'Inactive'\n",
        "    genuine_new_df['Sub Status'] = 'New'\n",
        "\n",
        "\n",
        "    return genuine_new_df, existing_customers_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FDcCK1SqN8N0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Execution\n",
        "\n",
        "The following section demonstrates how to:\n",
        "1. Load the master dataset from an Excel file.\n",
        "2. Load new and existing customer logs from CSV files.\n",
        "3. Preprocess the data.\n",
        "4. Apply fuzzy matching to classify and clean customer records.\n",
        "5. Consolidate the data and export the final result to an Excel workbook."
      ],
      "metadata": {
        "id": "fcKzxVV5SeTl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Example usage\n",
        "excel_file = \"master dumy.xlsx\"\n",
        "sheet_name = \"master dumy\"\n",
        "data = extract_data_from_sheet(excel_file, sheet_name)\n",
        "master_df=pd.DataFrame(data[1:],columns=data[0])\n",
        "new_customer_df=pd.read_csv(\"New Customer Log.csv\")\n",
        "existing_customers_df = pd.read_csv(\"Existing Cutomer log.csv\")\n",
        "\n",
        "\n",
        "# Preprocess customer names and FPR fields\n",
        "master_df = preprocess_column(master_df, 'Customer Name','FPR')\n",
        "new_customer_df = preprocess_column(new_customer_df, 'Customer Name','Name')\n",
        "existing_customers_df = preprocess_column(existing_customers_df, 'Customer Name','Name')\n",
        "\n",
        "\n",
        "\n",
        "# Example usage (assuming your CSV files are in the same directory)\n",
        "clean_existing_customers,mail_df=classify_existing_customer(existing_customers_df,master_df )\n",
        "\n",
        "# Get lists of master customer names and process new customers\n",
        "\n",
        "genuine_new_df, new_existing_customers_df = classify_new_customers(master_df, new_customer_df)\n",
        "genuine_new_df[\"Customer_type\"]=\"new\"\n",
        "new_existing_customers_df[\"Customer_type\"]=\"existing\"\n",
        "clean_existing_customers[\"Customer_type\"]=\"existing\"\n",
        "mail_df[\"Customer_type\"]=\"new\"\n",
        "\n",
        "\n",
        "Visit_df=pd.concat([genuine_new_df,clean_existing_customers,new_existing_customers_df,mail_df],axis=0)\n",
        "\n",
        "# Sort by 'Date'\n",
        "Visit_df.sort_values(by=\"For date\", inplace=True)\n",
        "# Drop duplicate rows based on a subset of columns(it will only include one entry if the user input same cusotmer in the same da)\n",
        "Visit_df.drop_duplicates(subset=['Name', 'For date', 'Customer Name'], inplace=True)\n",
        "\n",
        "# Define the file name for the workbook\n",
        "file_name = \"Data_Report.xlsx\"\n",
        "\n",
        "# Use ExcelWriter to write multiple sheets\n",
        "with pd.ExcelWriter(file_name, engine='openpyxl') as writer:\n",
        "    Visit_df.to_excel(writer, sheet_name='Visit Data', index=False)\n",
        "    genuine_new_df.to_excel(writer, sheet_name='Genuine New Data', index=False)\n",
        "    mail_df.to_excel(writer, sheet_name='Mail Data', index=False)\n",
        "\n",
        "print(f\"Data successfully written to {file_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jQBKGIVN8Qv",
        "outputId": "666c26f5-ad5c-4e7d-a765-4afa6b0edad8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Suggested match for 'abc food corp': 'abc food corporation' Under john doe (Score: 79)\n",
            "Replace? (yes/no): yes\n",
            "Replaced 'abc food corp' with 'abc food corporation' under john doe\n",
            "Auto-corrected 'xyz retailers' to 'xyz retailers' under jane smith (Score: 100)\n",
            "Suggested match for 'pqr restaurants': 'pqr restaurants pvt. ltd.' Under david lee (Score: 75)\n",
            "Replace? (yes/no): yes\n",
            "Replaced 'pqr restaurants' with 'pqr restaurants pvt. ltd.' under david lee\n",
            "Cleaning complet for existing customers\n",
            "Potential Match Found:\n",
            "New Customer: abc foods\n",
            "Master Dataset Match: abc foods under john doe (Score: 100)\n",
            "No customers found for FPR: emily white. Skipping fuzzy matching for 'pqr restaurant'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-68a3413333b5>:29: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  Visit_df=pd.concat([genuine_new_df,clean_existing_customers,new_existing_customers_df,mail_df],axis=0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "- **Data Extraction:** Reads master data from an Excel sheet and customer logs from CSV files.\n",
        "- **Preprocessing:** Standardizes customer names and salesperson identifiers.\n",
        "- **Fuzzy Matching:** Uses fuzzy matching to correct and classify customer names with auto-correction for high-confidence matches and user prompts for ambiguous cases.\n",
        "- **Consolidation & Export:** Merges the processed records and exports them into an organized Excel report.\n",
        "\n",
        "This enhanced version includes detailed documentation and markdown cells to improve readability and maintainability. Feel free to adjust thresholds, add further error handling, or modify the logic as needed for your specific use case."
      ],
      "metadata": {
        "id": "4VxCgFqDXSjv"
      }
    }
  ]
}